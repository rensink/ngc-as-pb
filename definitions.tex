\section{Morphism-based conditions}
 
In this section we recall the standard notion of nested condition, using a formulation that will make the connection with the variation proposed in this paper stand out. Here and in the remainder of the paper, we will mostly omit the term ``nested'' and just refer to \emph{conditions}; however, to distinguish them from our variation, we will refer to the standard notion of nested conditions as \emph{morphism-based}.

The definitions below use \emph{objects} and \emph{arrows} as building blocks. These can for now be thought of as the objects and arrows of any category $\bC$; however, our examples and intuitions will all be based on $\graph$.

For a given root object $R$, the set of morphism-based branches over $R$ is denoted $\MB{R}$, and the set of morphism-based conditions over in $R$ is denoted $\MC R$. They are inductively defined as follows:

\begin{definition}[morphism-based condition]\dlabel{mb condition}
  Given a root object $R$:
  \begin{itemize}
  \item A \emph{morphism-based condition} over $R$ is a pair $(R,\cB)$ where $\cB\subseteq \MB R$ is a finite set of morphism-based branches over $R$.
  \item A \emph{morphism-based branch} over $R$ is a pair $(r,c)$ where $r: R\func S$ is an arrow and $c\in \MC S$ is a morphism-based condition over $S$.
  \end{itemize}
\end{definition}
%
\emph{Terminology and notation:} We use $c,d$ to range over conditions and $p,q$ to range over branches. We use $R_c,\cB_c$ to refer to the root and branches of a condition $c$, and $R_p,r_p,S_p,c_p$ to refer to the root, arrow, subcondition root and subcondition of a branch $p$. We will also occasionally enumerate the elements of $\cB_c$ and directly write $c=(R_c, \setof{(r_i, c_i)}_{1\leq i\leq n})$ with $n=|\cB_c|$.
%
\begin{figure}
  \centering
  \input{figs/mb-condition}
  \caption{Pictorial representation of a morphism-based condition}
  \flabel{mb-condition}
\end{figure}

\medskip\noindent A condition expresses a property of arrows from its root to an arbitrary object. This is operationalised through the notion of \emph{satisfaction}.

\begin{definition}[satisfaction of morphism-based conditions]\dlabel{mb-satisfaction}
  Let $c$ be an mb-condition and $g:R_c\func G$ an arrow from $c$'s root to an object $G$. We say that \emph{$g$ satisfies $c$}, denoted $g\sat c$, if there is a branch $b\in \cB_c$ and an arrow $h:S_b\func G$ such that
  \begin{itemize}
  \item $g=r_b;h$
  \item $h\nsat c_b$.
  \end{itemize}
\end{definition}
%
\emph{Terminology and notation.} We call $b$ the \emph{responsible branch} and $h$ the \emph{witness} for $g\sat C$. Pictorially, $g\sat c$ with responsible branch $(r_i,c_i)$ and witness $h$ can be visualised as in \fcite{mb-satisfaction}.
%
\begin{figure}
  \centering
  \input{figs/mb-satisfaction}
  \caption{Pictorial representation of $g\sat c$}
  \flabel{mb-satisfaction}
\end{figure}

\medskip\noindent The notion of \emph{morphism} of nested conditions has not received much attention in the literature. Given the fact that an mb-condition is essentially a diagram in the category $\bC$, it is natural to imagine that a morphism from $c$ to $d$ should essentially be morphism between their diagrams, involving arrows from objects of $c$ to objects of $d$ such that the subdiagrams commute. However, since the semantics of conditions is really expressed by the notion of satisfaction, we want this to be preserved by morphisms, in some precise sense. For that to be the case, we need a more refined notion of morphism that plays well with the second clause of \dref{mb-satisfaction} in which there is a negation.

\begin{definition}[morphism-based condition morphism]\dlabel{mb-morphism}
  Given two mb-conditions $c,d$, an mb-condition morphism $m$ from $c$ to $d$ is a pair $(t:R_c\func R_d,\setof{m_p}_{p\in \cB_c})$ such that for all branches $p\in \cB_c$ there is a branch $q\in \cB_d$ with:
  \begin{enumerate}
  \item $m_p$ an (mb-condition) morphism from $c_q$ to $c_p$;
  \item $t;r_q;t_{m_p}=r_p$.
  \end{enumerate}
\end{definition}
%
Hence, a morphism consists of a \emph{top} arrow $t$ from the root of the source condition to that of the target condition, and for each branch $p$ of the source condition a \emph{backward} morphism $m_p$ from some branch $q$ of the target condition. We sometimes call $q$ the \emph{source branch} of $m_p$. Pictorially, $m$ can be visualised as in \fcite{mb-morphism}.
%
\begin{figure}
  \centering
  \input{figs/mb-morphism}
  \caption{Pictorial representation of a morphism-based condition morphism $m:c\func d$}
  \flabel{mb-morphism}
\end{figure}

\medskip\noindent Morphisms have the expected properties: identities and composition exist and form a monoid.
%
\begin{definition}[morphism-based composition identity]\dlabel{mb-identity}
  Given a mb-condition $c=(R,\cB)$, the identity $\id_c:c\func c$ is defined as $(\id_R,\setof{\id_{m_b}}_{b\in \cB})$.
\end{definition}

\begin{definition}[morphism-based condition morphism composition]\dlabel{mb-composition}
Given two mb-condition morphisms $m:c\func d$ and $n:d\func e$, their composition is defined as $m;n=(t_m;t_n,\setof{n_{q_p};m_p}_{p\in \cB_c})$ where for each $p\in \cB_c$, $q_p\in \cB_d$ is the source branch of $m_p$.
\end{definition}

\section{Span-based conditions}

We now present one the main idea of this paper based on the observation that there is a lot of duplication in a nested condition: the children of a node essentially contain all the structure of that (parent) node, and add some constraints on top of it. It turns out to be possible to avoid this duplication by only specifying the \emph{additional} structure. This is achieved by replacing the branch morphisms $r_b$ by \emph{spans}.


\begin{definition}[span-based condition]\dlabel{sb-condition}
  Given a root object $R$:
  \begin{itemize}
  \item A \emph{span-based condition} over $R$ is a pair $(R,\cB)$ where $\cB\subseteq \SB R$ is a finite set of span-based branches over $R$.
  \item A \emph{morphism-based branch} over $R$ is a pair $(u,d,c)$ where $u:I\func R,d:I\func S$ is a span (with interface $I$) and $c\in \SC S$ is a span-based condition over $S$.
  \end{itemize}
\end{definition}
%

\begin{definition}[span-based condition]\dlabel{sb-condition}
  A \emph{span-based condition} $c$ is a pair $(R,\setof{(u_i,d_i,C_i)}_{1\leq i\leq n}}$ where $A$ is an object called the \emph{root} of $C$, $n\geq 0$ is the \emph{degree} of $C$, and for all $1\leq i\leq n$, $C_i$ is a decomposed condition and $u_i\colon I_i\ifunc A$ and $d_i\colon I_i\func A_i$ form a span of arrows from an interface $I_i$ to $A$, respectively the root $A_i$ of $C_i$.
\end{definition}
%
\emph{Terminology and notation:} As before, we use $A_C$ to denote the root of a decomposed condition, and $u^C_i,d^C_i,C_i$ for the elements of a branch $(u_i,d_i,C_i)$, omitting $C$ if this does not cause confusion. The degree of $C$ is denoted $\degr C$. $u_i$ stands for the \emph{up-arrow} (which is always mono) and $d_i$ for the \emph{down-arrow} of the interface $I_i$. Pictorially, $C$ can be visualised as in \fcite{decomposed condition}.
%
\begin{figure}
  \centering
  \input{figs/decomposed-condition}
  \caption{Pictorial representation of a decomposed condition}
  \flabel{decomposed condition}
\end{figure}
%
As we will see later, the morphisms $f_i$ of a nested condition can be reconstructed by taking the pushout over the spans $A_C\cnufi I_i\func A_{C_i}$.

\medskip\noindent\emph{Note to self: I like to try and find another term for ``decomposed condition''. Maybe ``split condition''?}

\medskip\noindent Decomposed conditions come with a modified notation of satisfaction.

\begin{definition}[satisfaction of decomposed conditions]\dlabel{decomposed satisfaction}
  Let $C$ be a decomposed condition and $g:A_C\func G$ an arrow from $C$'s root to an object $G$. We say that \emph{$g$ satisfies $C$}, denoted $g\sat C$, if there is a branch $(u,d,C')\in C$ and an arrow $h:A_{C'}\func G$ such that
  \begin{enumerate}
  \item $u;g=d;h$
  \item $h\nsat C'$.
  \end{enumerate}
\end{definition}
%

\emph{Terminology and notation.} Like before, we call $(u,d,C')\in C$ the \emph{responsible branch} and $h$ the \emph{witness} of $g\sat C$. Pictorially, $g\sat C$ with responsible branch $(u_i,d_i,C_i)$ and witness $h$ can be visualised as in \fcite{decomposed satisfaction}.
%
\begin{figure}
  \centering
  \input{figs/decomposed-satisfaction}
  \caption{Pictorial representation of $g\sat C$ for a decomposed condition $C$}
  \flabel{decomposed satisfaction}
\end{figure}

\medskip\noindent
Decomposed conditions have a notion of morphism.

\begin{definition}[decomposed condition morphism]\dlabel{decomposed morphism}
  Given two decomposed conditions $C,D$, a morphism $m$ from $C$ to $D$ is a pair $\tupof{t:A_C\func A_D,\setof{(k_{ic},m_{ic})}_{1\leq ic\leq \degr C}}$ such that for all $1\leq ic\leq \degr C$, there is a $1\leq id\leq \degr D$ with
  \begin{enumerate}
  \item $k_{ic}$ an arrow from $I_{id}^D$ to $I_{ic}^C$;
  \item $m_{ic}$ a (decomposed condition) morphism from $D_{id}$ to $C_{ic}$;
  \item $k_{ic};u_{ic}^C;t_m=u_{id}^D$.
  \item $k_{ic}i;d_{ic}^C=d_{id}^D;t_{m_{ic}}$.
  \end{enumerate}
\end{definition}
%
\emph{Notation and terminology:} If $C,D$ are decomposed conditions, we write $m:C\func D$ to denote that $m$ is a morphism from $C$ to $D$. We also write $t_m$ and $m_i$ for the components of $t$. Pictorially, $m$ can be visualised as in \fcite{decomposed morphism}.
%
\begin{figure}
  \centering
  \input{figs/decomposed-morphism}
  \caption{Pictorial representation of a decomposed condition morphism $m:C\func D$}
  \flabel{decomposed morphism}
\end{figure}

\medskip\noindent
\emph{Note to self: I find it surprising that there are no conditions on $k_i$ except for the confluence equations. For instance, $k_i,d_j^D$ is \emph{not} necessarily a pullback of $t_{m_i},d_i^C$ (\excite{no pullback} below); in fact, $k_i$ is \emph{not even} uniquely determined by the two confluence equations (\excite{k not unique} below); in other words, there may be multiple morphisms from $C$ to $D$ that only differ in their $k$ components. I am however not sure if $k$ itself should be part of the morphism, or we should merely require its existence.}

\medskip\noindent Decomposed condition morphisms have the expected properties: identities and composition exist and have the expected properties.

\begin{definition}[decomposed condition identity morphism]
\end{definition}

\begin{definition}[decomposed condition morphism composition]
  If $m_1:C_1\func C_2$ and $m_2:C_2\func C_3$ are morphisms with $m_i=\tupof{t_i,\setof{(k_{i,j},m_{i,j})}_{1\leq j\leq \degr{C_i}}}$ for $i=1,2$, then their composition $m_1;m_2$ is defined by $\tupof{t_1;t_2,\setof{(k'_j,m'_j)}_{1\leq j\leq \degr{C_1}}}$ with for all $1\leq j\leq \degr{C_1}$:
  \begin{itemize}
  \item $k'_j=k_{2,x_j};k_{1,j}$
  \item $m'_j=m_{2,x_j};m_{1,j}$
  \end{itemize}
  where $1\leq x_j\leq \degr{C_2}$ is such that $(k_{2,x_j},m_{2,x_j})$ is the element from $m_2$ 
\end{definition}

\begin{proposition}
\end{proposition}

\medskip\noindent An important property of decomposed condition morphisms is that they \emph{preserve satisfaction}, in the following sense:
%
\begin{proposition}[morphisms preserve satisfaction]\plabel{morphism preserves satisfaction}
If $C,D$ are decomposed conditions with morphism $m:C\func D$, then $t_m;g\sat C$ implies $g\sat D$.
\end{proposition}
%
\emph{Proof.} By induction. Assume that $(u_i^C,d_i^C,C_i)$ is the branch of $C$ (hence the induction hypothesis is that the proposition holds for $C_i$) and $h^C\colon A_{C_i}\func G$ the morphism responsible for satisfaction; hence $u_i^C;t_m;g=d_i^C;h^C$ and $h^C\nsat C_i$. Moreover, let $(u_j^D,d_j^D,D_j)$ be the branch of $D$ with arrow $k_i\colon I_j^D\func I_i^C$ and morphism $m_i:D_j\func C_i$ as stipulated in \dcite{decomposed morphism}. This is visualised in \fcite{morphism preserves satisfaction}.
%
\begin{figure}
  \centering
  \input{figs/morphism-preserves-satisfaction}
  \caption{$t_m;g\sat C$ with a morphism $m:C\rightarrow D$}
  \flabel{morphism preserves satisfaction}
\end{figure}

Now $h^D=t_{m_i};h^C$ can be shown to satisfy the conditions for $h$ in \dcite{decomposed satisfaction} to be a witness for $g\sat D_j$:
\begin{enumerate}
\item $u_j^D;g = k_i;u_i^C;t_m;g= k_i;d_i^C;h^C = d_j^D;t_{m_i};h^C=d_j^D;h^D$.
\item Suppose that $h^D\sat D_j$, meaning $t_{m_i};h^C\sat D_j$; then by the induction hypothesis and the fact that $m_i$ is a morphism, it follows that $h^C\sat C_i$, which is in contradiction with the initial assumption of this proof. Hence $h^D\nsat D_j$.
\end{enumerate}
%
\subsection{Interface enrichment: A satisfaction invariant trasformation}

\begin{itemize}
  \item Remind to introduce ``condition branch''
  \item Shift of decomposed conditions along an arrow
  \item Prop(?): shift does not change satisfaction?
  \item Notation: given condition branch $C$ and interface $u = k;v$, we build $C_{\triangleleft k, v}$
  \item The construction
  \item Proposition: the contructions does not change satisfaction.
  \item Trasnforming a decomposed condition into an equivalent morphism-based one: apply the ``maximal'' enrichment top-bottom everywhere.
\end{itemize}  


\subsection{Decomposing nested conditions}

